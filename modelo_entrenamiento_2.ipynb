{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "modelo entrenamiento 2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JahazielHernandezHoyos/Traductor-de-Lenguaje-de-Se-as/blob/main/modelo_entrenamiento_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TOHu4VUAJFgO",
        "outputId": "8852b35f-6bee-46d7-ddf5-6ea81b776ea8"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "#Descarga y extracción del set de datos\n",
        "print(\"Descargando ZIP de datos\")\n",
        "url = 'https://download852.mediafire.com/kuogorh7prfg/yft23f6ipy9kfus/Base_de_datos_manos.zip'\n",
        "carpeta_zip = tf.keras.utils.get_file('Base_de_datos_manos.zip', origin=url, extract=True)\n",
        "\n",
        "#Variables para rutas en disco\n",
        "carpeta_base = os.path.join(os.path.dirname(carpeta_zip), 'Base_de_datos_manos')\n",
        "carpeta_entrenamiento = os.path.join(carpeta_base, 'Entrenamiento')\n",
        "carpeta_validacion = os.path.join(carpeta_base, 'Validacion')\n",
        "\n",
        "carp_entren_derecha = os.path.join(carpeta_entrenamiento, 'entrenamiento derecha')  # imagenes de mano derecha para pruebas\n",
        "carpeta_entren_izquierda = os.path.join(carpeta_entrenamiento, 'entrenamiento izquierda')  # imagenes de mano izquierda para pruebas\n",
        "carpeta_val_derecha = os.path.join(carpeta_validacion, 'validacion derecha')  # imagenes para validacion mano derecha\n",
        "carpeta_val_izquierda = os.path.join(carpeta_validacion, 'validacion izquierda')  # imagenes para validacion mano izquierda\n",
        "\n",
        "#Guardar el numero de datos de entrenamiento para cada cosa\n",
        "num_izquierda_entren = len(os.listdir(carp_entren_derecha))\n",
        "num_derecha_entren = len(os.listdir(carpeta_entren_izquierda))\n",
        "num_izquierda_val = len(os.listdir(carpeta_val_derecha))\n",
        "num_derecha_val = len(os.listdir(carpeta_val_izquierda))\n",
        "total_entrenamiento = num_izquierda_entren + num_derecha_entren\n",
        "total_val = num_izquierda_val + num_derecha_val\n",
        "\n",
        "TAMANO_LOTE = 200\n",
        "TAMANO_IMG = 200"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Descargando ZIP de datos\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "in3OdvpUG_9_"
      },
      "source": [
        "\n",
        "\n",
        "#Aumento de datos (escala, rotacion, blabla)\n",
        "print(\"Realizando aumento de datos\")\n",
        "image_gen_entrenamiento = ImageDataGenerator(\n",
        "      rescale=1./255,\n",
        "      rotation_range=40,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest')\n",
        "\n",
        "#Generacion de datos de entrenamiento FTW\n",
        "data_gen_entrenamiento = image_gen_entrenamiento.flow_from_directory(batch_size=TAMANO_LOTE,\n",
        "                                                     directory=carpeta_entrenamiento,\n",
        "                                                     shuffle=True,\n",
        "                                                     target_size=(TAMANO_IMG,TAMANO_IMG),\n",
        "                                                     class_mode='binary')\n",
        "\n",
        "#Generacion de datos de validacion\n",
        "image_gen_val = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "data_gen_validacion = image_gen_val.flow_from_directory(batch_size=TAMANO_LOTE,\n",
        "                                                 directory=carpeta_validacion,\n",
        "                                                 target_size=(TAMANO_IMG, TAMANO_IMG),\n",
        "                                                 class_mode='binary')\n",
        "\n",
        "#Modelo!\n",
        "modelo = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "\n",
        "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "\n",
        "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dense(2)\n",
        "])\n",
        "\n",
        "#Compilación\n",
        "modelo.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "#Entrenar la red. Toma un buen rato! Ve por un café ;)\n",
        "#Oye suscribete al canal!\n",
        "print(\"Entrenando modelo...\");\n",
        "epocas=60\n",
        "history = modelo.fit_generator(\n",
        "    data_gen_entrenamiento,\n",
        "    steps_per_epoch=int(np.ceil(total_entrenamiento / float(TAMANO_LOTE))),\n",
        "    epochs=epocas,\n",
        "    validation_data=data_gen_validacion,\n",
        "    validation_steps=int(np.ceil(total_val / float(TAMANO_LOTE)))\n",
        ")\n",
        "\n",
        "print(\"Modelo entrenado!\");"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6aK5pBaeNBd"
      },
      "source": [
        "#Exportar el modelo en formato h5\n",
        "modelo.save('perros-gatos.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uAHnDcF9WuQP"
      },
      "source": [
        "#El equipo es Linux. Listemos el contenido de la carpeta actual para ver que se exporto el modelo\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UzpZjGgUWuN7"
      },
      "source": [
        "#Para convertirlo a tensorflow.js, primero debemos instalar la libreria\n",
        "!pip install tensorflowjs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2v5uaQ_BWuLL"
      },
      "source": [
        "#Crear carpeta donde se colocaran los archivos resultantes\n",
        "!mkdir carpeta_salida"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_rtgd1_WuGk"
      },
      "source": [
        "#Realizar la exportacion a la carpeta de salida\n",
        "!tensorflowjs_converter --input_format keras perros-gatos.h5 carpeta_salida"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kd99qwADW4qt"
      },
      "source": [
        "#Confirmar que en la carpeta de salida se hayan generado los archivos. Deben aparecer archivos \"bin\" y \"json\"\n",
        "!ls carpeta_salida"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HeDA6P0CW4oa"
      },
      "source": [
        "#Para descargarlos, da clic del lado izquierdo en el icono de la carpeta\n",
        "#y expande carpeta_salida. En los archivos utiliza los 3 puntos para descargarlos"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}